{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toki-Pona-ChatGLM-Finetune\n",
    "\n",
    "This notebook implements finetuning of ChatGLM on Toki Pona content to attempt to produce an LLM capable of speaking Toki Pona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dataset.GLM \n",
    "import torch\n",
    "import loralib as lora\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import DataLoader\n",
    "from lora_utils.insert_lora import get_lora_model\n",
    "import dataset.GLM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "device = 'cpu'\n",
    "checkpoint = \"THUDM/chatglm-6b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, trust_remote_code=True, revision = 'main')\n",
    "model = AutoModel.from_pretrained(checkpoint, trust_remote_code=True, revision = 'main')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = {\n",
    "    'r': 8,\n",
    "    'lora_alpha':16,\n",
    "    'lora_dropout':0.1,\n",
    "    'enable_lora':[True, False, True],\n",
    "}\n",
    "\n",
    "model = get_lora_model(model, lora_config)\n",
    "model.load_state_dict(torch.load('saved/chatglm-6b_alpaca_5.pt'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset.GLM.device = device\n",
    "#dataset.GLM.pad_to = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    {'prompt':'toki!', 'completion':'toki! mi pona tan ni: mi sona e sina.'}\n",
    "]\n",
    "pairs_encoded = dataset.GLM.encode_pairs(pairs, tokenizer)\n",
    "train_dataset = dataset.GLM.SimpleDataset(pairs_encoded)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, collate_fn = dataset.GLM.collate_fn, shuffle=True, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.half().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {k: v.to(device) for k, v in next(iter(train_dataloader)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(**batch).loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    {'prompt':'toki!', 'completion':'toki! mi pona tan ni: mi sona e sina.'}\n",
    "]\n",
    "\n",
    "pairs_encoded = dataset.GLM.encode_pairs(pairs, tokenizer, with_eos=False)\n",
    "test_dataset = dataset.GLM.SimpleDataset(pairs_encoded)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, collate_fn = dataset.GLM.collate_fn, shuffle=True, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {k: v.to(device) for k, v in next(iter(test_dataloader)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "    **batch, \n",
    "    max_length=1024,\n",
    "    eos_token_id=130005,\n",
    "    do_sample=True,\n",
    "    temperature=0.55,\n",
    "    top_p = 0.75,\n",
    "    top_k = 10000,\n",
    "    repetition_penalty=1.5, \n",
    "    num_return_sequences=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for output in outputs:\n",
    "    print(tokenizer.sp_tokenizer.decode(output))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
